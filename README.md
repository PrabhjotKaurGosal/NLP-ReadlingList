# NLP-ReadlingList

Natural Language Processing (NLP) is a fast growing area of reserach. In the past year, I have seen many companies releasing new and powerful models. This repository contains reserach papers and other reading material that I found interesting and helpful during my reserach in this field. My current reserach project is on language translation (focusing on speech to speech translation). Therefore, most of the reading material below belongs to that area, with some exceptions. 
(PS: By no means is this list complete. I will continue to update the list as I learn more.)

My plan is to add a summary for the research papers as I finish reading them.

## History on Large Language Models (LLM)
1. Beyond Words: Large Language Models Expand AI’s Horizon (Oct 10, 2022): https://blogs.nvidia.com/blog/2022/10/10/llms-ai-horizon/ 
2. NVIDIA SPEEDS UP LARGE LANGUAGE MODELING (July 29, 2022): https://www.nextplatform.com/2022/07/29/nvidia-speeds-up-large-language-modeling/
3. Youtube video: https://www.youtube.com/watch?v=lnA9DMvHtfI

## Large Language Models 
1. **Gopher**: Scaling Language Models: Methods, Analysis & Insights from Training Gopher (Dec, 2021): https://storage.googleapis.com/deepmind-media/research/language-research/Training%20Gopher.pdf
   - https://gpt3demo.com/apps/deepmind-gopher
   - 280B parameters
   - https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval
2. **LaMDA**: Language Models for Dialog Applications (Feb, 2022): https://arxiv.org/pdf/2201.08239.pdf
   - https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html
3. **Chinchilla**: Training Compute-Optimal Large Language Models (March, 2022): https://arxiv.org/pdf/2203.15556.pdf
   - https://gpt3demo.com/apps/chinchilla-deepmind
   - https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training
5. **OPT**: Open Pre-trained Transformer Language Models (May, 2022): https://arxiv.org/pdf/2205.01068.pdf
   - 175B- parameters
   - https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/
   - Small pretrained model available: https://github.com/facebookresearch/metaseq 
6. **GLaM**: Efficient Scaling of Language Models with Mixture-of-Experts (Aug, 2022): https://arxiv.org/pdf/2112.06905.pdf
   - https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html
7. **PaLM**: Scaling Language Modeling with Pathways (Oct, 2022): https://arxiv.org/pdf/2204.02311.pdf
   - 540B parameters
   - https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html
8. **BLOOM**: A 176B-Parameter Open-Access Multilingual Language ModelPaper (Dec, 2022): https://arxiv.org/pdf/2211.05100.pdf
   - Can generate text in 46 natural languages and 13 programming languages.
   - https://bigscience.huggingface.co/blog/bloom
   - Model available: 




## Misc
1. Partnering people with large language models to find and fix bugs in NLP systems (May, 2022): https://www.microsoft.com/en-us/research/blog/partnering-people-with-large-language-models-to-find-and-fix-bugs-in-nlp-systems/
2. Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the World’s Largest and Most Powerful Generative Language Model: https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/
